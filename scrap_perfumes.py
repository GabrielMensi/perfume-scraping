

import os
import sys

print("=" * 50)
print("ğŸš€ SCRAPER DE PERFUMES - INICIANDO")
print("=" * 50)

# Verificar versiÃ³n de Python
print(f"ğŸ Python {sys.version}")

try:
    print("ğŸ“¦ Importando librerÃ­as...")
    import requests
    print("  âœ“ requests")
    
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    print("  âœ“ selenium")
    
    from webdriver_manager.chrome import ChromeDriverManager
    print("  âœ“ webdriver-manager")
    
    from selenium.webdriver.common.by import By
    print("  âœ“ selenium.webdriver.common.by")
    
    import time
    print("  âœ“ time")
    
    print("âœ… Todas las librerÃ­as importadas correctamente")
    
except ImportError as e:
    print(f"âŒ Error importando librerÃ­as: {e}")
    print("\nğŸ’¡ SoluciÃ³n:")
    print("Ejecuta: pip install requests beautifulsoup4 selenium webdriver-manager")
    input("\nPresiona Enter para salir...")
    exit(1)
except Exception as e:
    print(f"âŒ Error inesperado: {e}")
    input("\nPresiona Enter para salir...")
    exit(1)

BASE_URL = "https://www.perfumesdeoriente.com.ar/perfumes/?mpage=17"
IMG_DIR = "imagenes_productos"

try:
    os.makedirs(IMG_DIR, exist_ok=True)
    print(f"ï¿½ Carpeta de imÃ¡genes: {os.path.abspath(IMG_DIR)}")
except Exception as e:
    print(f"âŒ Error creando carpeta: {e}")
    input("Presiona Enter para salir...")
    exit(1)

try:
    # ConfiguraciÃ³n Selenium headless
    print("âš™ï¸ Configurando navegador...")
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')

    # Usar webdriver-manager para descargar automÃ¡ticamente ChromeDriver
    print("ğŸ”§ Descargando ChromeDriver...")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    print("âœ… Navegador configurado correctamente")

except Exception as e:
    print(f"âŒ Error configurando el navegador: {e}")
    print("ğŸ’¡ AsegÃºrate de que Google Chrome estÃ© instalado")
    input("Presiona Enter para salir...")
    exit(1)

# Paso 1: Obtener links de productos desde la grilla
try:
    print("ğŸŒ Conectando a la pÃ¡gina web...")
    driver.get(BASE_URL)
    time.sleep(2)
    print("âœ… PÃ¡gina cargada correctamente")
    
    print("ğŸ” Buscando productos...")
    product_links = set()
    elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/productos/']")
    for el in elements:
        href = el.get_attribute('href')
        if href and '/productos/' in href:
            product_links.add(href)
    
    print(f"ğŸ“¦ Encontrados {len(product_links)} productos")
    
    if len(product_links) == 0:
        print("âš ï¸ No se encontraron productos. Verifica la URL y tu conexiÃ³n.")
        driver.quit()
        input("Presiona Enter para salir...")
        exit(1)
        
except Exception as e:
    print(f"âŒ Error accediendo a la pÃ¡gina: {e}")
    print("ğŸ’¡ Verifica tu conexiÃ³n a internet")
    driver.quit()
    input("Presiona Enter para salir...")
    exit(1)



import re

print("ğŸ–¼ï¸ Comenzando descarga de imÃ¡genes...")
total_productos = len(product_links)
contador = 0

for link in product_links:
    contador += 1
    try:
        print(f"[{contador}/{total_productos}] Procesando producto...")
        driver.get(link)
        time.sleep(2)
        
        # Extraer nombre del producto de la URL
        prod_name = re.sub(r"[^a-zA-Z0-9_-]", "", link.split("/")[-2])
        
        # Buscar enlaces <a> con href de imagen grande del slider
        a_tags = driver.find_elements(By.CSS_SELECTOR, "a[href]")
        img_urls = []
        for a in a_tags:
            href = a.get_attribute('href')
            if href and "/products/" in href and href.endswith("-1024-1024.webp"):
                # Normalizar URL si empieza con //
                if href.startswith("//"):
                    href = "https:" + href
                img_urls.append(href)
        
        if not img_urls:
            print(f"âš ï¸ No se encontraron imÃ¡genes para {prod_name}")
            continue
            
        # Descargar hasta 4 imÃ¡genes por producto
        for idx, src in enumerate(img_urls[:4]):
            nombre = f"{prod_name}_{idx+1}.webp"
            ruta = os.path.join(IMG_DIR, nombre)
            try:
                r = requests.get(src, timeout=10)
                r.raise_for_status()
                with open(ruta, 'wb') as f:
                    f.write(r.content)
                print(f"  âœ… Descargada: {nombre}")
            except Exception as e:
                print(f"  âŒ Error descargando {nombre}: {e}")
                
    except Exception as e:
        print(f"âŒ Error procesando producto {contador}: {e}")
        continue

driver.quit()
print(f"ğŸ‰ Scraping finalizado. Se procesaron {contador} productos.")
print(f"ğŸ“ Revisa la carpeta '{IMG_DIR}' para ver las imÃ¡genes descargadas.")
input("Presiona Enter para salir...")
